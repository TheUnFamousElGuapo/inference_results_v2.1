Full Validated Models on Intel Xeon Platinum 8380 Scalable processor
=====================

The below tables are models enabled by the Intel® Neural Compressor. 

Performance varies by use, configuration and other factors. See backup for configuration details. For more complete information about performance and benchmark results, visit www.intel.com/benchmarks

Performance results are based on testing as of ​​02/23/2022 and may not reflect all publicly available ​updates. No product or component can be absolutely secure.

Intel optimizations, for Intel compilers or other products, may not optimize to the same degree for non-Intel products.

Your costs may vary.

Intel technologies may require enabled hardware, software or service activation.

© Intel Corporation.  Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries.  Other names and brands may be claimed as the property of others​.​​

### TensorFlow 2.x models

<table>
<thead>
  <tr>
    <th rowspan="2">Framework</th>
    <th rowspan="2">version</th>
    <th rowspan="2">model</th>
    <th colspan="3">Accuracy</th>
    <th colspan="3">Performance<br>1s4c10ins1bs/throughput<br>(samples/sec)<br></th>
  </tr>
  <tr>
    <th>INT8</th>
    <th>FP32</th>
    <th>Acc Ratio[(INT8-FP32)/FP32]</th>
    <th>INT8</th>
    <th>FP32</th>
    <th>Performance Ratio[INT8/FP32]</th>
  </tr>
</thead>
<tbody>
  <tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>densenet121</td>
<td>73.57%</td>
<td>72.89%</td>
<td>0.93%</td>
<td>374.30</td>
<td>296.40</td>
<td>1.26x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>densenet161</td>
<td>76.24%</td>
<td>76.29%</td>
<td>-0.07%</td>
<td>216.60</td>
<td>163.90</td>
<td>1.32x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>densenet169</td>
<td>74.40%</td>
<td>74.65%</td>
<td>-0.33%</td>
<td>294.75</td>
<td>242.15</td>
<td>1.22x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>efficientnet_b0</td>
<td>77.81%</td>
<td>76.76%</td>
<td>1.37%</td>
<td>561.50</td>
<td>434.01</td>
<td>1.29x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>faster_rcnn_inception_resnet_v2</td>
<td>37.99%</td>
<td>38.33%</td>
<td>-0.89%</td>
<td>3.88</td>
<td>2.17</td>
<td>1.78x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>faster_rcnn_inception_resnet_v2_saved</td>
<td>37.90%</td>
<td>38.33%</td>
<td>-1.12%</td>
<td>3.88</td>
<td>2.17</td>
<td>1.79x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>faster_rcnn_resnet101</td>
<td>30.28%</td>
<td>30.39%</td>
<td>-0.36%</td>
<td>67.16</td>
<td>18.54</td>
<td>3.62x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>faster_rcnn_resnet101_saved</td>
<td>30.37%</td>
<td>30.39%</td>
<td>-0.07%</td>
<td>66.95</td>
<td>16.49</td>
<td>4.06x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>inception_resnet_v2</td>
<td>80.44%</td>
<td>80.40%</td>
<td>0.05%</td>
<td>265.70</td>
<td>133.92</td>
<td>1.98x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>inception_v1</td>
<td>70.48%</td>
<td>69.74%</td>
<td>1.06%</td>
<td>2192.55</td>
<td>1052.98</td>
<td>2.08x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>inception_v2</td>
<td>74.36%</td>
<td>73.97%</td>
<td>0.53%</td>
<td>1799.20</td>
<td>816.74</td>
<td>2.20x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>inception_v3</td>
<td>77.28%</td>
<td>76.75%</td>
<td>0.69%</td>
<td>923.76</td>
<td>386.05</td>
<td>2.39x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>inception_v4</td>
<td>80.40%</td>
<td>80.27%</td>
<td>0.16%</td>
<td>572.49</td>
<td>191.00</td>
<td>3.00x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>mask_rcnn_inception_v2</td>
<td>28.54%</td>
<td>28.72%</td>
<td>-0.63%</td>
<td>134.68</td>
<td>51.15</td>
<td>2.63x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>mask_rcnn_inception_v2_ckpt</td>
<td>28.54%</td>
<td>28.72%</td>
<td>-0.63%</td>
<td>134.74</td>
<td>50.79</td>
<td>2.65x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>mobilenetv1</td>
<td>71.79%</td>
<td>70.96%</td>
<td>1.17%</td>
<td>3633.27</td>
<td>1382.64</td>
<td>2.63x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>mobilenetv2</td>
<td>71.89%</td>
<td>71.76%</td>
<td>0.18%</td>
<td>2504.63</td>
<td>1418.82</td>
<td>1.77x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>resnet101</td>
<td>77.50%</td>
<td>76.45%</td>
<td>1.37%</td>
<td>853.41</td>
<td>342.71</td>
<td>2.49x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>resnet50_fashion</td>
<td>77.80%</td>
<td>78.12%</td>
<td>-0.41%</td>
<td>3742.45</td>
<td>1957.16</td>
<td>1.91x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>resnet50v1.0</td>
<td>74.11%</td>
<td>74.27%</td>
<td>-0.22%</td>
<td>1474.03</td>
<td>486.21</td>
<td>3.03x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>resnet50v1.5</td>
<td>76.82%</td>
<td>76.46%</td>
<td>0.47%</td>
<td>1224.52</td>
<td>414.92</td>
<td>2.95x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>resnetv2_101</td>
<td>72.67%</td>
<td>71.87%</td>
<td>1.11%</td>
<td>440.30</td>
<td>315.23</td>
<td>1.40x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>resnetv2_152</td>
<td>73.03%</td>
<td>72.37%</td>
<td>0.91%</td>
<td>305.00</td>
<td>216.73</td>
<td>1.41x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>resnetv2_50</td>
<td>70.33%</td>
<td>69.64%</td>
<td>0.99%</td>
<td>746.79</td>
<td>555.71</td>
<td>1.34x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>ssd_mobilenet_v1</td>
<td>22.97%</td>
<td>23.13%</td>
<td>-0.69%</td>
<td>866.75</td>
<td>450.34</td>
<td>1.92x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>ssd_mobilenet_v1_ckpt</td>
<td>22.99%</td>
<td>23.13%</td>
<td>-0.61%</td>
<td>867.26</td>
<td>386.89</td>
<td>2.24x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>ssd_resnet34</td>
<td>21.69%</td>
<td>22.09%</td>
<td>-1.81%</td>
<td>41.17</td>
<td>10.76</td>
<td>3.83x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>ssd_resnet50_v1</td>
<td>37.86%</td>
<td>38.00%</td>
<td>-0.37%</td>
<td>68.03</td>
<td>24.68</td>
<td>2.76x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>ssd_resnet50_v1_ckpt</td>
<td>37.81%</td>
<td>38.00%</td>
<td>-0.50%</td>
<td>68.75</td>
<td>20.70</td>
<td>3.32x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>vgg16</td>
<td>72.66%</td>
<td>70.89%</td>
<td>2.50%</td>
<td>624.03</td>
<td>172.04</td>
<td>3.63x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>2.7.0</td>
<td>vgg19</td>
<td>72.72%</td>
<td>71.01%</td>
<td>2.41%</td>
<td>542.61</td>
<td>141.44</td>
<td>3.84x</td>
</tr>

</tbody>
</table>


### TensorFlow 1.x models

<table>
<thead>
  <tr>
    <th rowspan="2">Framework</th>
    <th rowspan="2">version</th>
    <th rowspan="2">model</th>
    <th colspan="3">Accuracy</th>
    <th colspan="3">Performance<br>1s4c10ins1bs/throughput<br>(samples/sec)<br></th>
  </tr>
  <tr>
    <th>INT8</th>
    <th>FP32</th>
    <th>Acc Ratio[(INT8-FP32)/FP32]</th>
    <th>INT8</th>
    <th>FP32</th>
    <th>Performance Ratio[INT8/FP32]</th>
  </tr>
</thead>
<tbody>
  <tr>
<td>intel-tensorflow</td>
<td>1.15UP3</td>
<td>bert_base_mrpc</td>
<td>86.52%</td>
<td>86.52%</td>
<td>0.00%</td>
<td>255.77</td>
<td>136.04</td>
<td>1.88x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>1.15UP3</td>
<td>bert_large_squad</td>
<td>92.41</td>
<td>92.98</td>
<td>-0.61%</td>
<td>23.53</td>
<td>11.62</td>
<td>2.02x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>1.15UP3</td>
<td>inception_v1_slim</td>
<td>70.49%</td>
<td>69.77%</td>
<td>1.03%</td>
<td>1941.78</td>
<td>781.35</td>
<td>2.49x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>1.15UP3</td>
<td>inception_v2_slim</td>
<td>74.35%</td>
<td>73.98%</td>
<td>0.50%</td>
<td>1559.10</td>
<td>646.87</td>
<td>2.41x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>1.15UP3</td>
<td>inception_v3_slim</td>
<td>78.32%</td>
<td>77.99%</td>
<td>0.42%</td>
<td>918.83</td>
<td>282.69</td>
<td>3.25x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>1.15UP3</td>
<td>inception_v4_slim</td>
<td>80.30%</td>
<td>80.19%</td>
<td>0.14%</td>
<td>507.39</td>
<td>141.36</td>
<td>3.59x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>1.15UP3</td>
<td>resnet_v1_101_slim</td>
<td>77.52%</td>
<td>76.40%</td>
<td>1.47%</td>
<td>805.67</td>
<td>218.12</td>
<td>3.69x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>1.15UP3</td>
<td>resnet_v1_152_slim</td>
<td>77.08%</td>
<td>76.81%</td>
<td>0.35%</td>
<td>572.84</td>
<td>145.86</td>
<td>3.93x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>1.15UP3</td>
<td>resnet_v1_50_slim</td>
<td>76.38%</td>
<td>75.18%</td>
<td>1.60%</td>
<td>1446.45</td>
<td>403.51</td>
<td>3.58x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>1.15UP3</td>
<td>resnetv2_101_slim</td>
<td>72.62%</td>
<td>71.91%</td>
<td>0.99%</td>
<td>459.04</td>
<td>249.91</td>
<td>1.84x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>1.15UP3</td>
<td>resnetv2_152_slim</td>
<td>72.95%</td>
<td>72.40%</td>
<td>0.76%</td>
<td>326.76</td>
<td>169.80</td>
<td>1.92x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>1.15UP3</td>
<td>resnetv2_50_slim</td>
<td>70.47%</td>
<td>69.72%</td>
<td>1.08%</td>
<td>775.54</td>
<td>469.69</td>
<td>1.65x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>1.15UP3</td>
<td>vgg16_slim</td>
<td>72.78%</td>
<td>70.89%</td>
<td>2.67%</td>
<td>591.48</td>
<td>146.10</td>
<td>4.05x</td>
</tr><tr>
<td>intel-tensorflow</td>
<td>1.15UP3</td>
<td>vgg19_slim</td>
<td>72.60%</td>
<td>71.01%</td>
<td>2.24%</td>
<td>494.30</td>
<td>118.19</td>
<td>4.18x</td>
</tr>
</tbody>
</table>


### PyTorch models

<table>
<thead>
  <tr>
    <th rowspan="2">Framework</th>
    <th rowspan="2">version</th>
    <th rowspan="2">model</th>
    <th colspan="3">Accuracy</th>
    <th colspan="3">Performance<br>1s4c10ins1bs/throughput<br>(samples/sec)<br></th>
  </tr>
  <tr>
    <th>INT8</th>
    <th>FP32</th>
    <th>Acc Ratio[(INT8-FP32)/FP32]</th>
    <th>INT8</th>
    <th>FP32</th>
    <th>Performance Ratio[INT8/FP32]</th>
  </tr>
</thead>
<tbody>
  <tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>albert_base_mrpc</td>
<td>88.77%</td>
<td>88.50%</td>
<td>0.31%</td>
<td>31.28</td>
<td>27.45</td>
<td>1.14x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>barthez_mrpc</td>
<td>83.12%</td>
<td>83.81%</td>
<td>-0.82%</td>
<td>119.18</td>
<td>74.13</td>
<td>1.61x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>blendcnn</td>
<td>68.40%</td>
<td>68.40%</td>
<td>0.00%</td>
<td>5138.45</td>
<td>4672.94</td>
<td>1.10x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>camembert_base_mrpc</td>
<td>87.39%</td>
<td>86.82%</td>
<td>0.66%</td>
<td>173.50</td>
<td>99.62</td>
<td>1.74x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>ctrl_mrpc</td>
<td>82.00%</td>
<td>82.00%</td>
<td>0.00%</td>
<td>21.31</td>
<td>8.50</td>
<td>2.51x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>deberta_mrpc</td>
<td>91.48%</td>
<td>90.91%</td>
<td>0.63%</td>
<td>104.94</td>
<td>63.68</td>
<td>1.65x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>distilbert_base_mrpc</td>
<td>88.27%</td>
<td>89.16%</td>
<td>-1.00%</td>
<td>311.52</td>
<td>196.45</td>
<td>1.59x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>flaubert_mrpc</td>
<td>80.82%</td>
<td>80.19%</td>
<td>0.78%</td>
<td>356.18</td>
<td>300.38</td>
<td>1.19x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>inception_v3</td>
<td>69.43%</td>
<td>69.52%</td>
<td>-0.13%</td>
<td>472.93</td>
<td>216.80</td>
<td>2.18x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>longformer_mrpc</td>
<td>91.82%</td>
<td>91.46%</td>
<td>0.39%</td>
<td>20.72</td>
<td>16.65</td>
<td>1.24x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>mbart_wnli</td>
<td>56.34%</td>
<td>56.34%</td>
<td>0.00%</td>
<td>57.97</td>
<td>28.33</td>
<td>2.05x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>mobilenet_v2</td>
<td>70.54%</td>
<td>71.84%</td>
<td>-1.81%</td>
<td>782.34</td>
<td>532.65</td>
<td>1.47x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>peleenet</td>
<td>71.66%</td>
<td>72.10%</td>
<td>-0.62%</td>
<td>513.07</td>
<td>388.10</td>
<td>1.32x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>resnet18</td>
<td>69.57%</td>
<td>69.76%</td>
<td>-0.27%</td>
<td>828.53</td>
<td>402.89</td>
<td>2.06x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>resnet18_fx</td>
<td>69.57%</td>
<td>69.76%</td>
<td>-0.27%</td>
<td>833.23</td>
<td>383.38</td>
<td>2.17x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>resnet18_qat</td>
<td>69.83%</td>
<td>69.76%</td>
<td>0.09%</td>
<td>826.88</td>
<td>392.36</td>
<td>2.11x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>resnet18_qat_fx</td>
<td>69.85%</td>
<td>69.76%</td>
<td>0.12%</td>
<td>833.85</td>
<td>383.65</td>
<td>2.17x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>resnet50</td>
<td>75.98%</td>
<td>76.15%</td>
<td>-0.21%</td>
<td>515.56</td>
<td>194.38</td>
<td>2.65x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>resnet50_ipex</td>
<td>75.57%</td>
<td>76.15%</td>
<td>-0.75%</td>
<td>672.90</td>
<td>307.53</td>
<td>2.19x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>resnet50_qat</td>
<td>76.02%</td>
<td>76.15%</td>
<td>-0.17%</td>
<td>509.97</td>
<td>187.82</td>
<td>2.72x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>resnext101_32x8d</td>
<td>79.15%</td>
<td>79.31%</td>
<td>-0.20%</td>
<td>203.85</td>
<td>70.25</td>
<td>2.90x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>rnnt</td>
<td>92.47</td>
<td>92.54</td>
<td>-0.08%</td>
<td>78.90</td>
<td>18.81</td>
<td>4.19x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>roberta_base_mrpc</td>
<td>87.76%</td>
<td>88.18%</td>
<td>-0.48%</td>
<td>175.81</td>
<td>100.59</td>
<td>1.75x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>se_resnext50_32x4d</td>
<td>79.05%</td>
<td>79.08%</td>
<td>-0.04%</td>
<td>373.85</td>
<td>165.22</td>
<td>2.26x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>squeezebert_mrpc</td>
<td>87.25%</td>
<td>87.65%</td>
<td>-0.46%</td>
<td>171.52</td>
<td>145.03</td>
<td>1.18x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>ssd_resnet34_fx</td>
<td>19.51</td>
<td>19.63</td>
<td>-0.61%</td>
<td>28.74</td>
<td>7.28</td>
<td>3.95x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>ssd_resnet34_qat_fx</td>
<td>17.80%</td>
<td>17.30%</td>
<td>2.89%</td>
<td>291.32</td>
<td>99.99</td>
<td>2.91x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>transfo_xl_mrpc</td>
<td>82.09%</td>
<td>81.20%</td>
<td>1.09%</td>
<td>9.61</td>
<td>7.28</td>
<td>1.32x</td>
</tr><tr>
<td>pytorch</td>
<td>1.9.0+cpu</td>
<td>yolo_v3</td>
<td>24.46%</td>
<td>24.54%</td>
<td>-0.36%</td>
<td>99.827</td>
<td>37.337</td>
<td>2.67x</td>
</tr>
</tbody>
</table>

### PyTorch models

<table>
<thead>
  <tr>
    <th rowspan="2">Framework</th>
    <th rowspan="2">version</th>
    <th rowspan="2">model</th>
    <th colspan="3">Accuracy</th>
    <th colspan="3">Performance<br>1s4c10ins1bs/throughput<br>(samples/sec)<br></th>
  </tr>
  <tr>
    <th>INT8</th>
    <th>FP32</th>
    <th>Acc Ratio[(INT8-FP32)/FP32]</th>
    <th>INT8</th>
    <th>FP32</th>
    <th>Performance Ratio[INT8/FP32]</th>
  </tr>
</thead>
<tbody>
  <tr>
<td>pytorch</td>
<td>1.8.0+cpu</td>
<td>bert_base_cola</td>
<td>58.92%</td>
<td>59.07%</td>
<td>-0.26%</td>
<td>176.71</td>
<td>101.25</td>
<td>1.75x</td>
</tr><tr>
<td>pytorch</td>
<td>1.8.0+cpu</td>
<td>bert_base_mrpc</td>
<td>90.35%</td>
<td>90.41%</td>
<td>-0.07%</td>
<td>166.14</td>
<td>101.59</td>
<td>1.64x</td>
</tr><tr>
<td>pytorch</td>
<td>1.8.0+cpu</td>
<td>bert_base_mrpc_qat</td>
<td>89.30%</td>
<td>89.50%</td>
<td>-0.22%</td>
<td>181.32</td>
<td>102.55</td>
<td>1.77x</td>
</tr><tr>
<td>pytorch</td>
<td>1.8.0+cpu</td>
<td>bert_base_rte</td>
<td>69.53%</td>
<td>69.14%</td>
<td>0.56%</td>
<td>176.97</td>
<td>101.55</td>
<td>1.74x</td>
</tr><tr>
<td>pytorch</td>
<td>1.8.0+cpu</td>
<td>bert_base_sst-2</td>
<td>91.35%</td>
<td>91.83%</td>
<td>-0.52%</td>
<td>179.68</td>
<td>101.56</td>
<td>1.77x</td>
</tr><tr>
<td>pytorch</td>
<td>1.8.0+cpu</td>
<td>bert_base_sts-b</td>
<td>89.07%</td>
<td>89.76%</td>
<td>-0.77%</td>
<td>179.08</td>
<td>103.04</td>
<td>1.74x</td>
</tr><tr>
<td>pytorch</td>
<td>1.8.0+cpu</td>
<td>bert_large_cola</td>
<td>62.07%</td>
<td>62.83%</td>
<td>-1.21%</td>
<td>87.10</td>
<td>33.96</td>
<td>2.56x</td>
</tr><tr>
<td>pytorch</td>
<td>1.8.0+cpu</td>
<td>bert_large_mrpc</td>
<td>88.97%</td>
<td>89.91%</td>
<td>-1.05%</td>
<td>86.95</td>
<td>33.84</td>
<td>2.57x</td>
</tr><tr>
<td>pytorch</td>
<td>1.8.0+cpu</td>
<td>bert_large_qnli</td>
<td>91.54%</td>
<td>91.84%</td>
<td>-0.32%</td>
<td>89.92</td>
<td>33.84</td>
<td>2.66x</td>
</tr><tr>
<td>pytorch</td>
<td>1.8.0+cpu</td>
<td>bert_large_rte</td>
<td>72.27%</td>
<td>71.88%</td>
<td>0.54%</td>
<td>37.55</td>
<td>33.78</td>
<td>1.11x</td>
</tr>
</tbody>
</table>


### MXNet models

<table>
<thead>
  <tr>
    <th rowspan="2">Framework</th>
    <th rowspan="2">version</th>
    <th rowspan="2">model</th>
    <th colspan="3">Accuracy</th>
    <th colspan="3">Performance<br>1s4c10ins1bs/throughput<br>(samples/sec)<br></th>
  </tr>
  <tr>
    <th>INT8</th>
    <th>FP32</th>
    <th>Acc Ratio[(INT8-FP32)/FP32]</th>
    <th>INT8</th>
    <th>FP32</th>
    <th>Performance Ratio[INT8/FP32]</th>
  </tr>
</thead>
<tbody>
  <tr>
<td>mxnet</td>
<td>1.7.0</td>
<td>inceptionv3</td>
<td>77.73%</td>
<td>77.64%</td>
<td>0.11%</td>
<td>974.39</td>
<td>273.37</td>
<td>3.56x</td>
</tr><tr>
<td>mxnet</td>
<td>1.7.0</td>
<td>mobilenet1.0</td>
<td>71.69%</td>
<td>72.22%</td>
<td>-0.74%</td>
<td>7289.97</td>
<td>2584.76</td>
<td>2.82x</td>
</tr><tr>
<td>mxnet</td>
<td>1.7.0</td>
<td>mobilenetv2_1.0</td>
<td>70.78%</td>
<td>70.87%</td>
<td>-0.12%</td>
<td>5981.16</td>
<td>2145.92</td>
<td>2.79x</td>
</tr><tr>
<td>mxnet</td>
<td>1.7.0</td>
<td>resnet152_v1</td>
<td>78.21%</td>
<td>78.54%</td>
<td>-0.42%</td>
<td>561.44</td>
<td>149.04</td>
<td>3.77x</td>
</tr><tr>
<td>mxnet</td>
<td>1.7.0</td>
<td>resnet18_v1</td>
<td>70.02%</td>
<td>70.14%</td>
<td>-0.17%</td>
<td>3541.71</td>
<td>812.57</td>
<td>4.36x</td>
</tr><tr>
<td>mxnet</td>
<td>1.7.0</td>
<td>resnet50v1</td>
<td>76.08%</td>
<td>76.33%</td>
<td>-0.32%</td>
<td>1573.97</td>
<td>414.04</td>
<td>3.80x</td>
</tr><tr>
<td>mxnet</td>
<td>1.7.0</td>
<td>squeezenet1.0</td>
<td>56.74%</td>
<td>56.96%</td>
<td>-0.38%</td>
<td>4920.07</td>
<td>1481.78</td>
<td>3.32x</td>
</tr><tr>
<td>mxnet</td>
<td>1.7.0</td>
<td>ssd-mobilenet1.0</td>
<td>74.94%</td>
<td>75.54%</td>
<td>-0.79%</td>
<td>737.96</td>
<td>176.71</td>
<td>4.18x</td>
</tr>
</tbody>
</table>


### ONNX Models

<table>
<thead>
  <tr>
    <th rowspan="2">Framework</th>
    <th rowspan="2">version</th>
    <th rowspan="2">model</th>
    <th colspan="3">Accuracy</th>
    <th colspan="3">Performance<br>1s4c10ins1bs/throughput<br>(samples/sec)<br></th>
  </tr>
  <tr>
    <th>INT8</th>
    <th>FP32</th>
    <th>Acc Ratio[(INT8-FP32)/FP32]</th>
    <th>INT8</th>
    <th>FP32</th>
    <th>Performance Ratio[INT8/FP32]</th>
  </tr>
</thead>
<tbody>
<tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>alexnet</td>
<td>54.74%</td>
<td>54.79%</td>
<td>-0.09%</td>
<td>1182.08</td>
<td>507.93</td>
<td>2.33x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>bert_base_mrpc_dynamic</td>
<td>85.54%</td>
<td>86.03%</td>
<td>-0.57%</td>
<td>355.71</td>
<td>144.14</td>
<td>2.47x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>bert_base_mrpc_static</td>
<td>85.29%</td>
<td>86.03%</td>
<td>-0.86%</td>
<td>681.90</td>
<td>293.39</td>
<td>2.32x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>bert_squad_model_zoo</td>
<td>80.43</td>
<td>80.67</td>
<td>-0.29%</td>
<td>106.55</td>
<td>59.56</td>
<td>1.79x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>caffenet</td>
<td>56.19%</td>
<td>56.30%</td>
<td>-0.20%</td>
<td>1754.53</td>
<td>561.43</td>
<td>3.13x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>distilbert_base_mrpc</td>
<td>84.56%</td>
<td>84.56%</td>
<td>0.00%</td>
<td>1568.66</td>
<td>550.81</td>
<td>2.85x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>efficientnet</td>
<td>77.58%</td>
<td>77.70%</td>
<td>-0.15%</td>
<td>1091.30</td>
<td>935.77</td>
<td>1.17x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>fcn</td>
<td>64.66%</td>
<td>64.98%</td>
<td>-0.49%</td>
<td>18.24</td>
<td>12.63</td>
<td>1.44x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>googlenet-12</td>
<td>67.61%</td>
<td>67.79%</td>
<td>-0.27%</td>
<td>930.16</td>
<td>720.33</td>
<td>1.29x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>inception_v1</td>
<td>67.23%</td>
<td>67.24%</td>
<td>-0.01%</td>
<td>960.98</td>
<td>763.02</td>
<td>1.26x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>mobilebert_mrpc</td>
<td>85.54%</td>
<td>86.27%</td>
<td>-0.85%</td>
<td>766.13</td>
<td>651.07</td>
<td>1.18x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>mobilebert_squad_mlperf</td>
<td>89.84</td>
<td>90.02</td>
<td>-0.20%</td>
<td>92.29</td>
<td>81.50</td>
<td>1.13x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>mobilenet_v3_mlperf</td>
<td>75.59%</td>
<td>75.74%</td>
<td>-0.20%</td>
<td>2962.13</td>
<td>1880.56</td>
<td>1.58x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>resnet_v1_5_mlperf</td>
<td>76.13%</td>
<td>76.46%</td>
<td>-0.43%</td>
<td>845.61</td>
<td>496.12</td>
<td>1.70x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>resnet50_v1_5</td>
<td>72.28%</td>
<td>72.29%</td>
<td>-0.01%</td>
<td>859.07</td>
<td>494.28</td>
<td>1.74x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>resnet50-v1-12</td>
<td>74.76%</td>
<td>74.99%</td>
<td>-0.31%</td>
<td>1011.74</td>
<td>521.56</td>
<td>1.94x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>roberta_base_mrpc</td>
<td>88.73%</td>
<td>89.46%</td>
<td>-0.82%</td>
<td>696.59</td>
<td>282.72</td>
<td>2.46x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>shufflenet-v2-12</td>
<td>66.13%</td>
<td>66.36%</td>
<td>-0.35%</td>
<td>4575.88</td>
<td>2699.85</td>
<td>1.69x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>squeezenet</td>
<td>56.55%</td>
<td>56.87%</td>
<td>-0.56%</td>
<td>5119.43</td>
<td>3695.21</td>
<td>1.39x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>ssd_mobilenet_v1</td>
<td>22.21%</td>
<td>23.10%</td>
<td>-3.85%</td>
<td>731.38</td>
<td>624.29</td>
<td>1.17x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>ssd_mobilenet_v2</td>
<td>23.84%</td>
<td>24.68%</td>
<td>-3.40%</td>
<td>552.41</td>
<td>444.97</td>
<td>1.24x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>ssd-12</td>
<td>18.84%</td>
<td>18.98%</td>
<td>-0.74%</td>
<td>15.18</td>
<td>10.30</td>
<td>1.47x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>vgg16</td>
<td>66.53%</td>
<td>66.69%</td>
<td>-0.24%</td>
<td>141.56</td>
<td>121.22</td>
<td>1.17x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>vgg16_model_zoo</td>
<td>72.28%</td>
<td>72.40%</td>
<td>-0.17%</td>
<td>252.78</td>
<td>120.95</td>
<td>2.09x</td>
</tr><tr>
<td>onnxrt-runtime</td>
<td>1.8.0</td>
<td>zfnet</td>
<td>55.89%</td>
<td>55.96%</td>
<td>-0.13%</td>
<td>565.28</td>
<td>307.55</td>
<td>1.84x</td>
</tr>
</tbody>
</table>

### INC-ENGINE Models
<table>
<thead>
  <tr>
    <th rowspan="2">Backend</th>
    <th rowspan="2">model</th>
    <th colspan="3">Accuracy</th>
    <th colspan="3">Performance<br>1s4c10ins1bs/throughput<br>(samples/sec)<br></th>
  </tr>
  <tr>
    <th>INT8</th>
    <th>FP32</th>
    <th>Acc Ratio[(INT8-FP32)/FP32]</th>
    <th>INT8</th>
    <th>FP32</th>
    <th>Performance Ratio[INT8/FP32]</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>INC-ENGINE</td>
    <td>bert_base_mrpc</td>
    <td>82.35%</td>
    <td>83.09%</td>
    <td>-0.89%</td>
    <td>487.41</td>
    <td>140.978</td>
    <td>3.46x</td>
  </tr>
  <tr>
    <td>INC-ENGINE</td>
    <td>bert_base_nli_mean_tokens_stsb</td>
    <td>89.26%</td>
    <td>89.55%</td>
    <td>-0.32%</td>
    <td>504.147</td>
    <td>141.504</td>
    <td>3.56x</td>
  </tr>
  <tr>
    <td>INC-ENGINE</td>
    <td>bert_base_sparse_mrpc</td>
    <td>70.34%</td>
    <td>70.59%</td>
    <td>-0.35%</td>
    <td>507.585</td>
    <td>142.876</td>
    <td>3.55x</td>
  </tr>
  <tr>
    <td>INC-ENGINE</td>
    <td>bert_large_squad</td>
    <td>90.70</td>
    <td>90.87</td>
    <td>-0.19%</td>
    <td>45.32</td>
    <td>12.531</td>
    <td>3.62x</td>
  </tr>
  <tr>
    <td>INC-ENGINE</td>
    <td>distilbert_base_uncased_emotion</td>
    <td>93.85%</td>
    <td>94.20%</td>
    <td>-0.37%</td>
    <td>999.973</td>
    <td>283.975</td>
    <td>3.52x</td>
  </tr>
  <tr>
    <td>INC-ENGINE</td>
    <td>distilbert_base_uncased_mrpc</td>
    <td>84.07%</td>
    <td>84.07%</td>
    <td>0.00%</td>
    <td>996.79</td>
    <td>280.88</td>
    <td>3.55x</td>
  </tr>
  <tr>
    <td>INC-ENGINE</td>
    <td>distilbert_base_uncased_sst2</td>
    <td>90.14%</td>
    <td>90.25%</td>
    <td>-0.12%</td>
    <td>999.98</td>
    <td>283.96</td>
    <td>3.52x</td>
  </tr>
  <tr>
    <td>INC-ENGINE</td>
    <td>distilroberta_base_wnli</td>
    <td>56.34%</td>
    <td>56.34%</td>
    <td>0.00%</td>
    <td>1032.043</td>
    <td>291.782</td>
    <td>3.54x</td>
  </tr>
  <tr>
    <td>INC-ENGINE</td>
    <td>dlrm</td>
    <td>78.07%</td>
    <td>78.10%</td>
    <td>-0.04%</td>
    <td>54898.34</td>
    <td>48331.14</td>
    <td>1.14x</td>
  </tr>
  <tr>
    <td>INC-ENGINE</td>
    <td>finbert_financial_phrasebank</td>
    <td>82.68%</td>
    <td>82.80%</td>
    <td>-0.14%</td>
    <td>922.877</td>
    <td>272.751</td>
    <td>3.38x</td>
  </tr>
  <tr>
    <td>INC-ENGINE</td>
    <td>minilm_l6_h384_uncased_sst2</td>
    <td>89.33%</td>
    <td>90.14%</td>
    <td>-0.90%</td>
    <td>2690.501</td>
    <td>1002.695</td>
    <td>2.68x</td>
  </tr>
  <tr>
    <td>INC-ENGINE</td>
    <td>paraphrase_xlm_r_multilingual_v1_stsb</td>
    <td>86.71%</td>
    <td>87.23%</td>
    <td>-0.60%</td>
    <td>511.919</td>
    <td>142.851</td>
    <td>3.58x</td>
  </tr>
  <tr>
    <td>INC-ENGINE</td>
    <td>roberta_base_mrpc</td>
    <td>89.71%</td>
    <td>88.97%</td>
    <td>0.83%</td>
    <td>508.184</td>
    <td>142.483</td>
    <td>3.57x</td>
  </tr>
</tbody>
</table>

### BACKUP
<table>
<tr><th>System Configuration</th><th>Intel Xeon Platinum 8380 Scalable processor</th></tr>
<tr>
<td>Test Date</td>
<td>March 01 01:00:00 UTC 2022</td>
</tr><tr>
<td>Manufacturer</td>
<td>Intel Corporation</td>
</tr><tr>
<td>Product Name</td>
<td>WilsonCity</td>
</tr><tr>
<td>BIOS Version</td>
<td>WLYDCRB1.SYS.0025.D65.2106110056</td>
</tr><tr>
<td>OS</td>
<td>Ubuntu 20.04.1 LTS</td>
</tr><tr>
<td>Kernel</td>
<td>5.4.0-77-generic</td>
</tr><tr>
<td>Microcode</td>
<td>0x8d9522d4</td>
</tr><tr>
<td>CPU Model</td>
<td>Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz</td>
</tr><tr>
<td>Base Frequency</td>
<td>2.3GHZ</td>
</tr><tr>
<td>Thread(s) per Core</td>
<td>2</td>
</tr><tr>
<td>Core(s) per Socket</td>
<td>40</td>
</tr><tr>
<td>Socket(s)</td>
<td>2</td>
</tr><tr>
<td>Turbo</td>
<td>Enabled</td>
</tr><tr>
<td>Power & Perf Policy</td>
<td>Performance</td>
</tr><tr>
<td>Installed</td>
<td>512GB (16x32GB DDR4 3200MT/s [3200MT/s])</td>
</tr><tr>
<td>NIC Summary</td>
<td>I210 Gigabit Network Connection</td>
</tr><tr>
<td>Drive Summary</td>
<td>1x ST1000NX0423 931.5G,
1x INTEL_SSDSC2BB48 447.1G
1x INTEL_SSDSC2KG96 894.3G</td>
</tr><tr>
</table>
