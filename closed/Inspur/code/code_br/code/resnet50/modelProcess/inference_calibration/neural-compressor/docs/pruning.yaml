```
pruning:
  train:                    # Section "train" is optional. If user implements `pruning_func` and pass to `pruning_func` attribute of pruning instance, skip this section.
    start_epoch: 0
    end_epoch: 10
    iteration: 100
    frequency: 2

    dataloader:
      batch_size: 256
      dataset:
        ImageFolder:
          root: /path/to/imagenet/train
      transform:
        RandomResizedCrop:
          size: 224
        RandomHorizontalFlip:
        ToTensor:
        Normalize:
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
    criterion:
      CrossEntropyLoss:
        reduction: None
    optimizer:
      SGD:
        learning_rate: 0.1
        momentum: 0.9
        weight_decay: 0.0004
        nesterov: False

  approach:
    weight_compression:
      initial_sparsity: 0.0
      target_sparsity: 0.3
      pruners:
        - !Pruner
            initial_sparsity: 0.0
            target_sparsity: 0.97
            start_epoch: 0
            end_epoch: 2
            prune_type: basic_magnitude
            update_frequency: 0.1
            names: ['layer1.0.conv1.weight']
        - !Pruner
            start_epoch: 0
            end_epoch: 1
            prune_type: gradient_sensitivity
            update_frequency: 1
            names: [
                     'bert.encoder.layer.0.attention.output.dense.weight',
                   ]
            parameters: {
                          target: 8,
                          transpose: True,
                          stride: 64,
                          index: 0,
                          normalize: True,
                          importance_inputs: ['head_mask'],
                          importance_metric: abs_gradient
                        }

```
